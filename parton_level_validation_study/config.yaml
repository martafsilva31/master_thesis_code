## Parton-level config file for validation study

# Folder where to keep everything for MadMiner WH studies, on which we store Madgraph samples and all .h5 files (setup, analyzed events, ...)
main_dir: /lstore/titan/martafsilva/master_thesis/master_thesis_output/parton_level_validation_simplified_process

# Folder where to keep all the plots 
plot_dir: /lstore/titan/martafsilva/master_thesis/master_thesis_output/parton_level_validation_simplified_process/plots

# Name of setup file (without the .h5)
setup_file: setup 

#Name of the cards_folder
cards_folder_name: cards_simplified_process

# If running pythia, the path for the Pythia card
pythia_card: /cards/pythia8_card.dat

# Path for MadGraph installation
mg_dir: /cvmfs/sw.el7/gcc63/madgraph/3.3.1/b01/

# Whether to use all observables or a limited number of them; choices = 'all', "pt_w_only", "pt_w_and_cos_delta_plus"]
observable_set: all

# .h5 sample name to augment/train
sample_name: ud_wph_mu_smeftsim_lhe #choices ['wh_signalOnly_SMonly_noSysts_lhe','wh_withBackgrounds_SMonly_noSysts_lhe']

alices:

# Augmentation with alices (good idea for the training and testing to be consistent)
  augmentation:
    n_samples:  -1
    n_thetas:  1000
    priors: ['gaussian', 0, 0.4]  #['flat', -1.2, 1.2] #['gaussian', 0, 0.4] 
    prior_name:  gaussian_prior_0_0.4 #flat_prior_m1.2_p1.2 # "gaussian_prior_0_0.4"
    n_processes:  8

  training:
    observables:  "kinematic_only"
    n_hidden: [50,]
    activation:  "relu"
    training_samples_name: gaussian_prior_0_0.4 #flat_prior_m1.2_p1.2  #"gaussian_prior_0_0.4"
    alpha: 5
    n_workers: 8
    n_samples:  -1
    n_epochs: 50
    batch_size: 128
    nestimators: 5 #number of estimators for ALICES method NN ensemble

  testing:
    observables:  "kinematic_only"
    n_samples:  100
    n_thetas:  100
    n_processes:  8
    priors: ['gaussian', 0, 0.4]   #['flat', -1.2, 1.2] #['gaussian', 0, 0.2] #['flat', -1.2, 1.2] #['gaussian', 0, 0.4] 
    prior_name: gaussian_prior_0_0.4_100_samples #gaussian_prior_0_0.2 # flat_prior_m1.2_p1.2 # "gaussian_prior_0_0.4"
    n_processes:  8
    

alice:

  training:
    observables:  "kinematic_only"
    n_hidden: [50,]
    activation:  "relu"
    training_samples_name: gaussian_prior_0_0.4 #flat_prior_m1.2_p1.2  #"gaussian_prior_0_0.4"
    n_workers: 8
    n_samples:  -1
    n_epochs: 50
    batch_size: 128
    nestimators: 5 #number of estimators for ALICES method NN ensemble
  
  testing:
    observables:  "kinematic_only"
    n_samples:  1000
    n_thetas:  1000
    n_processes:  8
    priors: ['flat', -1.2, 1.2]  #['flat', -1.2, 1.2] #['gaussian', 0, 0.2] #['flat', -1.2, 1.2] #['gaussian', 0, 0.4] 
    prior_name: gaussian_prior_0_0.4_100_samples #gaussian_prior_0_0.4_1000_samples #gaussian_prior_0_0.2 # flat_prior_m1.2_p1.2 # "gaussian_prior_0_0.4"
    n_processes:  8
    
sally:

  augmentation:
    n_samples:  -1


# Augmentation with alices (good idea for the training and testing to be consistent)
  training:
    observables:  "kinematic_only"
    n_hidden: [50,]
    activation:  "relu"
    n_workers: 4
    n_samples:  -1
    n_epochs: 50
    batch_size: 128
    nestimators: 5 #number of estimators for ALICES method NN ensemble

  testing:
    observables:  "kinematic_only"
    n_samples:  1000
    n_thetas:  1000
    n_processes:  8
    prior_name: sally #gaussian_prior_0_0.2 # flat_prior_m1.2_p1.2 # "gaussian_prior_0_0.4"
    n_processes:  8

###### Plotting - limits

limits:

  # what to use to extract the limits, given as input to the expected_limits function, choices = ['rate','histo','sally', 'ml']
  mode: ml

  # which of the training observable sets to use when extracting limits from a ALICES, ALICE or ml  method
  observables: kinematic_only

  prior: gaussian_prior_0_0.4 # for sally prior name equal to sally

  # which of the architecture model (for each of the input variable configurations) to use
  model: alices_hidden_[50]_relu_alpha_5_epochs_50_bs_128_same_data

  #ALICE, ALICES or SALLY
  method: alices

  # if the limits are derived in shape-only histograms (i.e. without Poisson likelihood term)
  shape_only: False 
  
  # which of the observables to use in the x-axis if extracting limits from histograms; required='histo' 
  observable_x: None

  # which of the observables to use in the y-axis if extracting limits from histograms; required='histo'
  observable_y: None

  # binning of the variable in the x-axis (can either be a standard observable or output of the ALICES/ALICE/SALLY network), type=float
  binning_x: None 

  # binning of the variable in the y-axis, type=float
  binning_y: None

  # whether or not to do histograms of likelihood in log_scale
  do_log: False

  # process charge+flavor inclusive samples',type=int
  lumi: 300

  # turns on debug functions
  debug: False

  grid_ranges: [-1.2,1.2]

  grid_resolutions: 300